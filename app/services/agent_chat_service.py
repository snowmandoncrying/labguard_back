import os
from typing import List, Dict, Optional
from dotenv import load_dotenv, find_dotenv
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.agents import initialize_agent, Tool, AgentType
from langchain_core.documents import Document
from pydantic import BaseModel, Field
import time
import json
from datetime import datetime
from app.schemas.query import ManualSearchInput
from app.services.chat_log_service import chat_log_service
import uuid
from sqlalchemy.orm import Session
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv_path = find_dotenv()
if dotenv_path:
    load_dotenv(dotenv_path=dotenv_path)
else:
    load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CHROMA_DIR = "./chroma_db"
EXPERIMENT_LOG_FILE = "./experiment_logs.json"

# ì‹¤í—˜ ë¡œê·¸ ê´€ë¦¬ í´ë˜ìŠ¤
class ExperimentLogger:
    def __init__(self, log_file: str = EXPERIMENT_LOG_FILE):
        self.log_file = log_file
        self.experiments = self.load_experiments()
    
    def load_experiments(self) -> List[Dict]:
        try:
            if os.path.exists(self.log_file):
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"ë¡œê·¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []
    
    def save_experiments(self):
        try:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(self.experiments, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ë¡œê·¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def add_experiment_log(self, user_id: str, content: str, experiment_type: str = "progress"):
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "user_id": user_id,
            "type": experiment_type,  # progress, result, observation, issue
            "content": content
        }
        self.experiments.append(log_entry)
        self.save_experiments()
        return log_entry
    
    def get_user_experiments(self, user_id: str, limit: int = 10) -> List[Dict]:
        user_logs = [exp for exp in self.experiments if exp.get("user_id") == user_id]
        return user_logs[-limit:]
    
    def generate_report(self, user_id: str) -> str:
        user_logs = self.get_user_experiments(user_id, limit=50)
        if not user_logs:
            return "ê¸°ë¡ëœ ì‹¤í—˜ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report = f"=== ì‹¤í—˜ ì§„í–‰ ë³´ê³ ì„œ (ì´ {len(user_logs)}ê°œ í•­ëª©) ===\n\n"
        
        # íƒ€ì…ë³„ ë¶„ë¥˜
        progress_logs = [log for log in user_logs if log.get("type") == "progress"]
        result_logs = [log for log in user_logs if log.get("type") == "result"]
        observation_logs = [log for log in user_logs if log.get("type") == "observation"]
        issue_logs = [log for log in user_logs if log.get("type") == "issue"]
        
        if progress_logs:
            report += "ğŸ“‹ **ì‹¤í—˜ ì§„í–‰ ìƒí™©:**\n"
            for log in progress_logs[-5:]:  # ìµœê·¼ 5ê°œë§Œ
                report += f"- {log['timestamp'][:16]}: {log['content']}\n"
            report += "\n"
        
        if result_logs:
            report += "ğŸ“Š **ì‹¤í—˜ ê²°ê³¼:**\n"
            for log in result_logs[-5:]:
                report += f"- {log['timestamp'][:16]}: {log['content']}\n"
            report += "\n"
        
        if observation_logs:
            report += "ğŸ” **ê´€ì°° ì‚¬í•­:**\n"
            for log in observation_logs[-5:]:
                report += f"- {log['timestamp'][:16]}: {log['content']}\n"
            report += "\n"
        
        if issue_logs:
            report += "âš ï¸ **ì´ìŠˆ ë° ë¬¸ì œì :**\n"
            for log in issue_logs[-5:]:
                report += f"- {log['timestamp'][:16]}: {log['content']}\n"
            report += "\n"
        
        return report

# ì‹¤í—˜ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
experiment_logger = ExperimentLogger()

# LLM ê¸°ë°˜ ë©”ì‹œì§€ íƒ€ì… ë¶„ë¥˜ í•¨ìˆ˜
def llm_classify_message_type(message: str) -> str:
    """
    LLM(GPT-4o ë“±)ì„ ì‚¬ìš©í•´ ë©”ì‹œì§€ê°€ 'ì§ˆë¬¸'ì¸ì§€ 'ì‹¤í—˜ê¸°ë¡'ì¸ì§€ ë¶„ë¥˜í•œë‹¤.
    ë°˜ë“œì‹œ 'ì§ˆë¬¸' ë˜ëŠ” 'ì‹¤í—˜ê¸°ë¡' ë‘˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•œë‹¤.
    """
    llm = ChatOpenAI(model_name="gpt-4o-mini", openai_api_key=OPENAI_API_KEY, temperature=0)
    prompt = f"""
ì•„ë˜ ë©”ì‹œì§€ê°€ 'ì§ˆë¬¸'ì¸ì§€ 'ì‹¤í—˜ê¸°ë¡'ì¸ì§€ í•œ ë‹¨ì–´ë¡œ ë‹µí•´. 
ì§ˆë¬¸: ì‹¤í—˜ ë°©ë²•, ë§¤ë‰´ì–¼ ë“± ê¶ê¸ˆì¦. 
ì‹¤í—˜ê¸°ë¡: ì§„í–‰/ê´€ì°°/ê²°ê³¼/ì´ìŠˆ ë“±. 
ë°˜ë“œì‹œ 'ì§ˆë¬¸' ë˜ëŠ” 'ì‹¤í—˜ê¸°ë¡' ë‘˜ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µí•´. 
ë©”ì‹œì§€: {message}
"""
    result = llm.predict(prompt).strip().lower()
    # í˜¹ì‹œë¼ë„ LLMì´ ì—‰ëš±í•˜ê²Œ ë‹µí•  ê²½ìš° ë°©ì–´
    if "experiment" in result:
        return "experiment_log"
    return "message"

# ì‹¤í—˜ ë¡œê·¸ íƒ€ì… ë¶„ë¥˜
def classify_experiment_type(message: str) -> str:
    """ì‹¤í—˜ ë¡œê·¸ì˜ ì„¸ë¶€ íƒ€ì… ë¶„ë¥˜"""
    message_lower = message.lower()
    
    if any(keyword in message_lower for keyword in ["ê²°ê³¼", "ë°ì´í„°", "ì¸¡ì •ê°’", "ìˆ˜ì¹˜"]):
        return "result"
    elif any(keyword in message_lower for keyword in ["ê´€ì°°", "ë°œê²¬", "í™•ì¸", "ë³´ì˜€ì–´"]):
        return "observation"
    elif any(keyword in message_lower for keyword in ["ë¬¸ì œ", "ì´ìŠˆ", "ì‹¤íŒ¨", "ì˜¤ë¥˜", "ì•ˆë¨"]):
        return "issue"
    else:
        return "progress"

# manual_idë¡œ ë²¡í„°DBì—ì„œ ê²€ìƒ‰í•˜ëŠ” Tool ì •ì˜
def get_manual_search_tool(manual_id):
    def search_manual_func(input_text: str) -> str:
        print(f"[Tool] input_text: {input_text}")
        print(f"[Tool] manual_id: {manual_id}")
        start = time.time()
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectorstore = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings)
        docs = vectorstore.similarity_search(input_text, k=4, filter={"manual_id": manual_id})
        elapsed = time.time() - start
        print(f"[Tool] ê²€ìƒ‰ ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print(f"[Tool] ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")
        if not docs:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return "\n".join([doc.page_content for doc in docs])
    return Tool(
        name=f"manual_search_{manual_id}",
        func=search_manual_func,
        description=f"{manual_id} ë§¤ë‰´ì–¼ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤."
    )

def agent_chat_answer(manual_id: str, sender: str, message: str, user_id: str = "default_user", session_id: str = None, history: List[Dict[str, str]] = None) -> Dict[str, str]:
    """
    ê°œì„ ëœ ì—ì´ì „íŠ¸ ë‹µë³€ í•¨ìˆ˜ (LLM ê¸°ë°˜ ë©”ì‹œì§€ ë¶„ë¥˜)
    Returns: {"response": str, "type": str, "logged": bool, "session_id": str}
    """
    if history is None:
        history = []
    
    if not session_id:
        session_id = str(uuid.uuid4())

    # === LLM ê¸°ë°˜ ë©”ì‹œì§€ íƒ€ì… ë¶„ë¥˜ ===
    message_type = llm_classify_message_type(message)
    
    if message_type == "experiment_log":
        # ì‹¤í—˜ ë¡œê·¸ë¡œ ì²˜ë¦¬
        exp_type = classify_experiment_type(message)
        experiment_logger.add_experiment_log(user_id, message, exp_type)
        
        # ì‹¤í—˜ ë¡œê·¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
        responses = {
            "progress": ["ì‹¤í—˜ ì§„í–‰ ìƒí™©ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤! ê³„ì† ì§„í–‰í•˜ì‹œê³  ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”."],
            "result": ["ì‹¤í—˜ ê²°ê³¼ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤! í¥ë¯¸ë¡œìš´ ê²°ê³¼ë„¤ìš”. ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•˜ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”."],
            "observation": ["ê´€ì°° ë‚´ìš©ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì¢‹ì€ ê´€ì°°ì´ë„¤ìš”! ì´ëŸ° ì„¸ì‹¬í•œ ê´€ì°°ì´ ì‹¤í—˜ì˜ ì„±ê³µ ë¹„ê²°ì…ë‹ˆë‹¤."],
            "issue": ["ë¬¸ì œ ìƒí™©ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. í•´ê²° ë°©ë²•ì„ ë§¤ë‰´ì–¼ì—ì„œ ì°¾ì•„ë³¼ê¹Œìš”?"]
        }
        
        import random
        response = random.choice(responses.get(exp_type, responses["progress"]))
        
        return {
            "response": response,
            "type": "experiment_log",
            "logged": False, # This is not a Q&A chat log
            "session_id": session_id
        }
    else:
        # ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬ - RAG ë°©ì‹
        recent_logs = experiment_logger.get_user_experiments(user_id, limit=5)
        experiment_context = ""
        if recent_logs:
            experiment_context = "\\nìµœê·¼ ì‹¤í—˜ ì§„í–‰ ìƒí™©:\\n"
            for log in recent_logs:
                experiment_context += f"- {log['timestamp'][:16]}: {log['content']}\\n"
        
        system_prompt = f"""
ë„ˆëŠ” ì‹¤í—˜ì‹¤ ë§¤ë‰´ì–¼ QA ë„ìš°ë¯¸ì•¼.
manual_id {manual_id}ì— í•´ë‹¹í•˜ëŠ” ë§¤ë‰´ì–¼ë§Œ ê²€ìƒ‰í•´ì•¼ í•œë‹¤.
ë§¤ë‰´ì–¼ ë‚´ìš©ì„ ë²—ì–´ë‚˜ì§€ ë§ê³ , ëª¨ë¥´ëŠ” ê±´ ëª¨ë¥¸ë‹¤ê³  ë‹µí•´.
{experiment_context}
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë§¤ë‰´ì–¼ì„ ê²€ìƒ‰í•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì¤˜.
"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        llm = ChatOpenAI(model_name="gpt-4.1-mini", openai_api_key=OPENAI_API_KEY)
        tool = get_manual_search_tool(manual_id)
        
        agent = create_openai_functions_agent(llm, [tool], prompt)
        agent_executor = AgentExecutor(agent=agent, tools=[tool], verbose=True)

        chat_history_messages = []
        if history:
            for turn in history:
                if turn["role"] == "user":
                    chat_history_messages.append(HumanMessage(content=turn["content"]))
                elif turn["role"] == "assistant":
                    chat_history_messages.append(AIMessage(content=turn["content"]))

        response = agent_executor.invoke({
            "input": message,
            "chat_history": chat_history_messages
        })
        answer = response.get("output", "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # === ì±„íŒ… ë¡œê·¸ ì €ì¥ ===
        chat_log_service.add_chat_to_cache(
            session_id=session_id,
            user_id=user_id,
            manual_id=manual_id,
            sender='user',
            message=message
        )
        chat_log_service.add_chat_to_cache(
            session_id=session_id,
            user_id=user_id,
            manual_id=manual_id,
            sender='ai',
            message=answer
        )
        
        return {
            "response": answer,
            "type": "message",
            "logged": True,
            "session_id": session_id
        }

# DBì— ì €ì¥ë˜ì§€ ì•Šì€ ëª¨ë“  ì±„íŒ… ë¡œê·¸ë¥¼ ê°•ì œë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def flush_all_chat_logs():
    """Flushes all buffered chat logs from Redis to the database."""
    print("Attempting to flush all chat logs from Redis to DB...")
    chat_log_service.flush_chat_logs_from_cache_to_db()

def save_chat_log(db: Session, chat_log: dict):
    """
    (This function is now deprecated and replaced by the Redis caching mechanism)
    ë‹¨ì¼ ì±„íŒ… ë¡œê·¸ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    # db_chat_log = ChatLog(**chat_log)
    # db.add(db_chat_log)
    # db.commit()
    # db.refresh(db_chat_log)
    # return db_chat_log
    print("save_chat_log is deprecated. Use chat_log_service.add_chat_to_cache instead.")
    pass

# ì‹¤í—˜ ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜
def generate_experiment_report(user_id: str = "default_user") -> str:
    """ì‚¬ìš©ìì˜ ì‹¤í—˜ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„±"""
    return experiment_logger.generate_report(user_id)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    manual_id = "lab_manual_001"
    user_id = "researcher_001"
    
    # ì‹¤í—˜ ì§„í–‰ ìƒí™© ë¡œê·¸
    result1 = agent_chat_answer(manual_id, "researcher_001", "PCR ì‹¤í—˜ ì‹œì‘í–ˆì–´ìš”", user_id)
    print("Response 1:", result1)
    
    # ì§ˆë¬¸
    result2 = agent_chat_answer(manual_id, "researcher_001", "PCR ì˜¨ë„ëŠ” ëª‡ë„ë¡œ ì„¤ì •í•´ì•¼ í•˜ë‚˜ìš”?", user_id)
    print("Response 2:", result2)
    
    # ì‹¤í—˜ ê²°ê³¼ ë¡œê·¸
    result3 = agent_chat_answer(manual_id, "researcher_001", "PCR ê²°ê³¼ê°€ ë‚˜ì™”ëŠ”ë° ë°´ë“œê°€ íë¦¿í•˜ê²Œ ë‚˜ì™”ì–´ìš”", user_id)
    print("Response 3:", result3)
    
    # ë³´ê³ ì„œ ìƒì„±
    report = generate_experiment_report(user_id)
    print("Report:", report)
